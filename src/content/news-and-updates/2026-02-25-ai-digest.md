---
title: "AI digest: Big deals and bigger fights"
date: 2026-02-25
tags: [ai-news, digest, hardware, enterprise]
summary: "Meta throws $100B at AMD while Anthropic accuses Chinese labs of data theft."
draft: false
---

The AI world is splitting into two camps: those making massive hardware bets and those fighting over who's stealing from whom.

## Meta bets $100B on AMD to break Nvidia's grip

[Meta struck a massive deal with AMD](https://techcrunch.com/2026/02/24/meta-strikes-up-to-100b-amd-chip-deal-as-it-chases-personal-superintelligence/) for up to $100 billion in AI chips over multiple years, including a 160 million share warrant. This mirrors AMD's earlier OpenAI deal and shows the desperation to diversify away from Nvidia's stranglehold. Six gigawatts of compute power suggests Meta is serious about its "personal superintelligence" push, though whether AMD can actually deliver at scale remains the big question.

## Anthropic accuses Chinese labs of systematic data theft

[Anthropic claims DeepSeek, Moonshot, and MiniMax ran 16 million queries](https://the-decoder.com/anthropic-accuses-deepseek-moonshot-and-minimax-of-stealing-claudes-ai-data-through-16-million-queries/) to systematically extract Claude's capabilities for training their own models. This isn't just casual scraping, it's industrial-scale knowledge distillation. The timing is perfect given rumors that DeepSeek's next model was trained on banned Blackwell chips and could shake up the market again.

## Pentagon vs Anthropic hits the deadline

[The Pentagon gave Anthropic until Friday](https://techcrunch.com/2026/02/24/anthropic-wont-budge-as-pentagon-escalates-ai-dispute/) to loosen AI guardrails or face penalties. Anthropic isn't budging, which raises serious questions about government leverage when dealing with AI vendors. This could set precedent for how much control agencies actually have over commercial AI systems they want to use.

## Alibaba's Qwen 3.5 proves smaller can be smarter

[Qwen's new medium-sized models](https://www.marktechpost.com/2026/02/24/alibaba-qwen-team-releases-qwen-3-5-medium-model-series-a-production-powerhouse-proving-that-smaller-ai-models-are-smarter/) focus on architectural efficiency over raw parameter count. This matches the broader trend away from "bigger is always better" toward models that actually work in production. Smart move while everyone else burns cash on massive clusters.
